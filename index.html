<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Compositionality and Reasoning in AI and Cognitive Science — Workshop</title>
  <meta name="description" content="One-day workshop on Compositionality and Reasoning in AI and Cognitive Science — January 8, 2026 — Warsaw">

  <!-- Google fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">

  <style>
    :root{
      --accent:#0b63d4;
      --bg:#f7f9fc;
      --text:#17202a;
      --muted:#51657a;
      --max-width:980px;
    }
    *{box-sizing:border-box}
    body{font-family:Inter,system-ui,Segoe UI,Roboto,Arial,sans-serif;margin:0;color:var(--text);background:var(--bg);line-height:1.5}
    a{color:var(--accent);text-decoration:none}

    .container{max-width:var(--max-width);margin:0 auto;padding:28px}

    /* Navigation */
    nav{
      display:flex;
      justify-content:space-between;
      align-items:center;
      padding:12px 0;
      background:white;
      position:sticky;
      top:0;
      z-index:1000;
      border-bottom:1px solid #ddd;
    }
    .nav-links{display:flex;gap:14px;flex-wrap:wrap}

    /* Hero */
    .hero{
      position:relative;
      height:320px;
      display:flex;
      align-items:flex-end;
      border-radius:8px;
      overflow:hidden;
      background:#222;
      margin-bottom:24px;
    }
    .hero img{
      position:absolute;
      inset:0;
      width:100%;
      height:100%;
      object-fit:cover;
      filter:contrast(1.05) saturate(0.95);
    }
    .hero-overlay{
      position:relative;
      background:linear-gradient(180deg,rgba(0,0,0,0.10),rgba(0,0,0,0.45));
      padding:28px;
      color:white;
      width:100%;
    }
    .site-title{
      margin:0;
      font-size:clamp(20px,3.2vw,36px);
      line-height:1.05;
    }
    .site-sub{
      margin-top:6px;
      color:rgba(255,255,255,0.9);
      font-weight:400;
    }

    /* Sections */
    section{
      background:white;
      margin-top:18px;
      padding:28px;
      border-radius:8px;
      box-shadow:0 6px 18px rgba(19,30,43,0.04);
    }
    h2{margin-top:0}
    .muted{color:var(--muted)}
    ul{padding-left:1.1em}
    .speaker{margin-bottom:10px}

    footer {
      margin-top: 24px;
      text-align: center;
      padding: 20px;
      color: var(--muted);
      font-size: 13px;
      background: white;
      border-radius: 8px;
      box-shadow: 0 6px 18px rgba(19, 30, 43, 0.04);
    }

    /* Program */
    .program-list {
      list-style: none;
      padding: 0;
      margin: 0;
    }

    .program-item {
      display: grid;
      grid-template-columns: 110px 1fr;
      gap: 12px;
      margin-bottom: 10px;
    }

    .program-time {
      color: var(--muted);
      font-weight: normal;
    }

    .program-desc strong {
      font-weight: 600;
    }

    .program-desc em {
      font-style: italic;
    }

    /* make it tighter on phones */
    @media (max-width: 480px) {
      .program-item {
        grid-template-columns: 90px 1fr;
      }
    }

    /* Logo container styling */
    .logo-container {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 40px;
      margin-bottom: 10px;
      flex-wrap: wrap;
    }

    /* Individual logos */
    .logo-container img {
      height: 60px;
      width: auto;
      object-fit: contain;
      transition: transform 0.2s ease-in-out;
    }

    /* Optional hover effect */
    .logo-container img:hover {
      transform: scale(1.05);
    }

    :root{
      --accent:#0b63d4;
      --bg:#f7f9fc;
      --text:#17202a;
      --muted:#51657a;
      --max-width:980px;
    }
    *{box-sizing:border-box}
    body{font-family:Inter,system-ui,Segoe UI,Roboto,Arial,sans-serif;margin:0;color:var(--text);background:var(--bg);line-height:1.5}
    a{color:var(--accent);text-decoration:none}

    html {
      scroll-behavior: smooth; /* Smooth scrolling */
    }

    .container{max-width:var(--max-width);margin:0 auto;padding:28px}

    section {
      scroll-margin-top: 70px; /* Fix offset when clicking links */
    }
  </style>
</head>
<body>
  <div class="container">
    <nav>
      <div style="font-weight:700">Compositionality &amp; Reasoning — Workshop</div>
      <div class="nav-links muted">
        <a href="#about">About</a>
        <a href="#papers">Papers</a>
        <a href="#program">Program</a>
        <a href="#speakers">Speakers</a>
        <a href="#venue">Venue</a>
        <a href="#contact">Contact</a>
      </div>
    </nav>

    <!-- HERO -->
    <header class="hero" role="banner">
      <img src="images/header.jpg" alt="Workshop header image">
      <div class="hero-overlay">
        <h1 class="site-title">Compositionality and Reasoning in AI and Cognitive Science</h1>
        <div class="site-sub">Warsaw, January 8, 2026</div>
      </div>
    </header>

    <!-- About -->
    <section id="about">
      <h2>About the Workshop</h2>
      <p class="muted">
        <div style="text-align: justify;">
        In neural models, generalization is the ability to apply learned knowledge to new, unseen data. Compositionality is a principle that enables such generalization by allowing complex structures to be represented and processed as combinations of simpler elements, which provides a systematic way to interpret new structures. Together, they are a key factor in bridging the gap between learning and genuine adaptability in AI.<br>        
        This one‑day workshop aims to discuss compositionality, structured representation, and the integration of neural and symbolic reasoning in modern learning systems.
        </div>
      </p>

      <h3>Our research:</h3>
      <p class="muted">
          <div style="text-align: justify;">
          Our work investigates hybrid models of reasoning, a neuro-symbolic approach to deductive inference that integrates neural learning with symbolic logic within restricted fragments of natural language. We began with a pilot study [1] on a simple propositional corpus to examine whether neural networks can assist a symbolic prover by selecting necessary formulas from a knowledge base to prove a given hypothesis. We then extended this work [2] to the syllogistic fragment, evaluating feedforward, recurrent, convolutional, and transformer architectures. Despite the simplicity of the experimental setup—training and testing on a single knowledge base with one-hot encoded inputs—our results indicated that models trained from scratch failed to capture the underlying logical structure. To validate and extend these findings, we next employed modern pretrained language models for formula selection in direct and indirect proofs, integrating neural assistants with a symbolic prover to evaluate their interaction within a hybrid reasoning framework [3]. In this phase, models were trained on multiple knowledge bases and tested on unseen ones, using pseudoword-based textual representations for both input and output.
          To further investigate the compositionality limitation in neural models, and in collaboration with researchers from the University of Trento, we explored a meta-learning approach on our syllogistic corpus [4] to study how models adapt to novel reasoning patterns in the formula selection task.<br><br>
          Compositionality is a fundamental component of reasoning and continues to challenge neural models. Our results suggest that hybrid architectures integrating symbolic inference with neural learning offer a promising path toward overcoming these limitations and, more broadly, a compelling direction for future exploration—shedding light on how structured reasoning can emerge from pattern-based learning systems in AI.
          <br><br>
          The research project <a href="https://projekty.ncn.gov.pl/index.php?projekt_id=484631" target="_blank" style="color:var(--accent); text-decoration:none; font-weight:500;">
          “Hybrid Models of Reasoning”</a>, funded by the National Science Centre, Poland, is conducted by <strong>Maciej Malicki</strong> (University of Warsaw), <strong>Jakub Szymanik</strong> (University of Trento), and <strong>Manuel Vargas Guzmán</strong> (University of Warsaw).
          </div>
      </p>
    </section>

    <!-- Published Papers -->
    <section id="papers">
      <h2>Published Papers</h2>
      <ul style="list-style:none; padding-left:0;">
        <li style="margin-bottom:20px;">
          <strong><a href="https://hal.science/hal-03846838v1/document" target="_blank">[1] Compositionality in a simple corpus</a></strong>
          <details style="margin-top:6px;">
            <summary style="cursor:pointer; color:var(--accent);">Show Abstract</summary>
            <p class="muted" style="margin-top:6px; text-align: justify;">
              We investigate the capacity of neural networks (NNs) to learn compositional structures by focusing on a well-defined simple logical corpus, and on proof-centered compositionality. We conduct our investigation in a minimal setting by creating a simple logical corpus, where all compositionality-related phenomena come from the structure of proofs as all the sentences of the corpus are propositional logic implications. By training NNs on this corpus we test different aspects of compositionality, through variations of proof lengths and permutations of the constants.
            </p>
          </details>
        </li>

        <li style="margin-bottom:20px;">
          <strong><a href="https://aclanthology.org/2024.findings-naacl.147.pdf" target="_blank">[2] Testing the limits of logical reasoning in neural and hybrid models</a></strong>
          <details style="margin-top:6px;">
            <summary style="cursor:pointer; color:var(--accent);">Show Abstract</summary>
            <p class="muted" style="margin-top:6px; text-align: justify;">
              We study the ability of neural and hybrid models to generalize logical reasoning patterns. We created a series of tests for analyzing various aspects of generalization in the context of language and reasoning, focusing on compositionality and recursiveness. We used them to study the syllogistic logic in hybrid models, where the network assists in premise selection. We analyzed feed-forward, recurrent, convolutional, and transformer architectures. Our experiments demonstrate that even though the models can capture elementary aspects of the meaning of logical terms, they learn to generalize logical reasoning only to a limited degree.
            </p>
          </details>
        </li>

        <li style="margin-bottom:20px;">
          <strong><a href="https://arxiv.org/pdf/2510.09472" target="_blank">[3] Hybrid Models for Natural Language Reasoning: The Case of Syllogistic Logic</a></strong>
          <details style="margin-top:6px;">
            <summary style="cursor:pointer; color:var(--accent);">Show Abstract</summary>
            <p class="muted" style="margin-top:6px; text-align: justify;">
              Despite the remarkable progress in neural models, their ability to generalize—a cornerstone for applications like logical reasoning—remains a critical challenge. We delineate two fundamental aspects of this ability: compositionality, the capacity to abstract atomic logical rules underlying complex inferences, and recursiveness, the aptitude to build intricate representations through iterative application of inference rules. In the literature, these two aspects are often confounded together under the umbrella term of generalization. To sharpen this distinction, we investigated the logical generalization capabilities of pre-trained large language models (LLMs) using the syllogistic fragment as a benchmark for natural language reasoning. Though simple, this fragment provides a foundational yet expressive subset of formal logic that supports controlled evaluation of essential reasoning abilities. Our findings reveal a significant disparity: while LLMs demonstrate reasonable proficiency in recursiveness, they struggle with compositionality. To overcome these limitations and establish a reliable logical prover, we propose a hybrid architecture integrating symbolic reasoning with neural computation. This synergistic interaction enables robust and efficient inference—neural components accelerate processing, while symbolic reasoning ensures completeness. Our experiments show that high efficiency is preserved even with relatively small neural components. As part of our proposed methodology, this analysis gives a rationale and highlights the potential of hybrid models to effectively address key generalization barriers in neural reasoning systems.
            </p>
          </details>
        </li>

        <li style="margin-bottom:20px;">
          <strong><a href="https://arxiv.org/pdf/2505.14313" target="_blank">[4] Teaching Small Language Models to Learn Logic through Meta-Learning</a></strong>
          <details style="margin-top:6px;">
            <summary style="cursor:pointer; color:var(--accent);">Show Abstract</summary>
            <p class="muted" style="margin-top:6px; text-align: justify;">
              Large language models (LLMs) are increasingly evaluated on reasoning tasks, yet their logical abilities remain contested. To address this, we study LLMs' reasoning in a well-defined fragment of logic: syllogistic reasoning. We cast the problem as premise selection and construct controlled datasets to isolate logical competence. Beyond evaluation, an open challenge is enabling LLMs to acquire abstract inference patterns that generalize to novel structures. We propose to apply few-shot meta-learning to this domain, thereby encouraging models to extract rules across tasks rather than memorize patterns within tasks. Although meta-learning has been little explored in the context of logic learnability, our experiments show that it is effective: small models (1.5B-7B) fine-tuned with meta-learning demonstrate strong gains in generalization, with especially pronounced benefits in low-data regimes. These meta-learned models outperform GPT-4o and o3-mini on our syllogistic reasoning task. 
            </p>
          </details>
        </li>

      </ul>
    </section>

    <!-- Program -->
    <section id="program">
      <h2>Program</h2>
      <ul class="program-list">
        <li class="program-item">
          <div class="program-time">9:00–9:40</div>
          <div class="program-desc"><strong><a href="https://dieuwkehupkes.nl/" target="_blank" rel="noopener">Dieuwke Hupkes</a></strong> (Meta AI Research) <br> <em>TBA</em></div>
        </li>

        <li class="program-item">
          <div class="program-time">9:50–10:10</div>
          <div class="program-desc"><em>Coffee break</em></div>
        </li>

        <li class="program-item">
          <div class="program-time">10:20–11:00</div>
          <div class="program-desc"><strong><a href="https://marcinmilkowski.pl" target="_blank" rel="noopener">Marcin Miłkowski</a></strong> (Polish Academy of Sciences) <br> 
            <em>Composing Moves: How Procedural Memory Builds Novel Action</em>
          </div>
        </li>

        <li class="program-item">
          <div class="program-time">11:10–11:40</div>
          <div class="program-desc"><strong>Manuel Vargas Guzmán</strong> (University of Warsaw) <br> <em>TBA</em></div>
        </li>

        <li class="program-item">
          <div class="program-time">11:50–12:20</div>
          <div class="program-desc"><strong>Leonardo Bertolazzi</strong> (University of Trento) <br> <em>Logic, Plausibility, and Generalization: Making LLMs More Systematic</em></div>
        </li>

        <li class="program-item">
          <div class="program-time">12:20–14:00</div>
          <div class="program-desc"><em>Lunch break</em></div>
        </li>

        <li class="program-item">
          <div class="program-time">14:00–14:40</div>
          <div class="program-desc"><strong><a href="https://personalpages.manchester.ac.uk/staff/ian.pratt/" target="_blank" rel="noopener">Ian Pratt-Hartmann</a></strong> 
            (University of Manchester &amp; University of Opole) <br> <em>Natural Language Inference: from Aristotle to AI</em>
          </div>
        </li>

        <li class="program-item">
          <div class="program-time">14:50–15:30</div>
          <div class="program-desc"><strong><a href="https://andrea-de-varda.github.io" target="_blank" rel="noopener">Andrea de Varda</a></strong> (MIT) <br> 
            <em>Behavioral and structural signatures of human-like reasoning in LLMs</em>
          </div>
        </li>

        <li class="program-item">
          <div class="program-time">15:30–15:50</div>
          <div class="program-desc"><em>Coffee break</em></div>
        </li>

        <li class="program-item">
          <div class="program-time">15:50–16:30</div>
          <div class="program-desc"><strong><a href="https://sites.google.com/view/justyna-grudzinska/research?authuser=0" target="_blank" rel="noopener">Justyna Grudzińska-Zawadowska</a></strong> 
            (University of Warsaw) <br> <em>TBA</em>
          </div>
        </li>

        <li class="program-item">
          <div class="program-time">16:40–17:20</div>
          <div class="program-desc"><strong>Discussion</strong></div>
        </li>

      </ul>
    </section>

    <!-- Speakers -->
    <section id="speakers">
      <h2>Invited Speakers</h2>

      <div class="speaker">
        <strong><a href="https://dieuwkehupkes.nl/" target="_blank" rel="noopener">Dieuwke Hupkes</a></strong>
        (<span class="muted">Meta AI Research</span>)
        <p class="muted" style="margin-top:6px; text-align: justify;">            
          <em>TBA</em>
        </p>
      </div>
      
      <div class="speaker">
        <strong><a href="https://personalpages.manchester.ac.uk/staff/ian.pratt/" target="_blank" rel="noopener">Ian Pratt-Hartmann</a></strong>
        (<span class="muted">University of Manchester &amp; University of Opole</span>)
        <div><strong>Natural Language Inference: from Aristotle to AI</strong></div>
        <!-- <details style="margin-top:6px;">
          <summary style="cursor:pointer; color:var(--accent); font-size:0.9rem;">Show abstract</summary> -->
        <p class="muted" style="margin-top:6px; text-align: justify;">            
          <em>For most of recorded history, logic was seen as an attempt to
            systematize the entailment patterns observed in natural—that is to
            say, human—languages. Only with the rise of quantification theory
            and the emergence of mathematical logic at the end of the nineteenth
            century did the syntactic structure of natural language lose its
            pre-eminence. Recently, however, there has been a resurgence of
            interest in natural language reasoning, as a result of two very
            different developments. The first is the discovery of a rich,
            complexity-theoretic landscape among fragments of natural languages
            defined by the syntactic devices they feature: quantifying
            determiners, relative clauses, ditransitive verb, passive
            constructions, anaphora, and so on. The second is the recent rise of
            transformer-based language models, which can be fine-tuned to solve a
            range of natural language inference tasks. In this talk I combine both
            these strands of research to direct the spotlight back on logical
            systems based on natural, rather than, formal, languages. As I shall
            argue, the study of such systems opens up new avenues of logical
            research.
          </em>
        </p>
        </details>
      </div>      

      <div class="speaker">
        <strong><a href="https://andrea-de-varda.github.io" target="_blank" rel="noopener">Andrea de Varda</a></strong>
        (<span class="muted">MIT</span>)
        <div><strong>Behavioral and structural signatures of human-like reasoning in LLMs</strong></div>
        <p class="muted" style="margin-top:6px; text-align: justify;">            
          <em>What does it mean for a model to reason in a human-like way? A core signature of cognitive effort in psychology is reaction time: harder problems take longer because they require more intermediate steps. We show that large reasoning models capture this cost of thinking. Across seven reasoning domains, the length of a model's chain of thought predicts human reaction times, tracking both item-level difficulty and broader task-level demands. This alignment is robust across models and is substantially stronger for reasoning models than for base LLMs.

          Motivated by this correspondence in behavior, we ask whether similarities between humans and models extend to the internal organization of their reasoning systems. Intelligent behavior in humans is supported by a set of specialized brain networks that segregate language processing, domain-general reasoning, social reasoning, and intuitive physics. Drawing inspiration from neuroscience, we used task-based functional localization in LLMs to identify units that selectively respond to tasks in each of these domains. We found that the units' selectivity profiles exhibit the same within-domain overlap and across-domain separability observed in the human brain.

          Together, these findings show that LLMs and their reasoning-optimized variants not only mirror patterns of cognitive effort but also develop emergent functional structure reminiscent of the modular architecture supporting human thought.</em>
        </p>
      </div>

      <div class="speaker">
        <strong><a href="https://marcinmilkowski.pl" target="_blank" rel="noopener">Marcin Miłkowski</a></strong>
        (<span class="muted">Polish Academy of Sciences</span>)
        <div><strong>Composing Moves: How Procedural Memory Builds Novel Action</strong></div>
        <p class="muted" style="margin-top:6px; text-align: justify;">           
          <em>Compositionality is fundamental to both human and artificial cognition, yet theories of procedural memory often underestimate its representational demands. This presentation argues that any adequate account of skilled action must satisfy three conceptual desiderata rooted in compositionality: method-specific directivity (disambiguating kinematically equivalent execution paths), hierarchical sequencing (implementing conditional branching and nested timing), and dual error evaluation (distinguishing execution noise from content mismatch). Empirical patterns from apraxia research—where patients execute isolated movements but cannot combine them into novel tool-use sequences or meaningless gestures—reveal compositionality as a distinct theoretical requirement, not a product of associative learning. The analysis demonstrates that anti-representationalist appeals to "smooth coping" or affordance-responsiveness evade these constraints by masking the necessary representational architecture. Action guidance requires hybrid concepts merging descriptive properties with directive force; otherwise, the interface between linguistic instruction and motor execution remains unexplained. By articulating the minimal conceptual requirements for procedural memory, this framework compels both embodied cognition and artificial intelligence research to confront the compositional logic of action, precluding theoretical shortcuts and establishing a foundation for genuine practical rationality in biological and artificial agents.</em>
        </p>
      </div>

      <div class="speaker">
        <strong><a href="https://sites.google.com/view/justyna-grudzinska/research?authuser=0" target="_blank" rel="noopener">Justyna Grudzińska-Zawadowska</a></strong>
        (<span class="muted">University of Warsaw</span>)
        <p class="muted" style="margin-top:6px; text-align: justify;">            
          <em>TBA</em>
        </p>
      </div>

      <div class="speaker">
        <strong>Leonardo Bertolazzi</strong>
        (<span class="muted">University of Trento</span>)
        <div><strong>Logic, Plausibility, and Generalization: Making LLMs More Systematic</strong></div>
        <p class="muted" style="margin-top:6px; text-align: justify;">            
          <em>Large language models (LLMs) can now tackle a wide range of complex tasks once exclusive to human intelligence, including mathematics, programming, and social and emotional reasoning. However, this impressive performance is often paired with surprising failures and a lack of systematicity. In this talk, I argue that we can learn valuable lessons from studies of human cognition to better understand and improve these capabilities in LLMs. I will present two applications of cognitively-inspired approaches, each addressing a different aspect of systematic reasoning in LLMs: 1. Investigating content effects in deductive reasoning. This line of work challenges the idea that LLMs learn to reason formally by examining how semantic content influences LLM performance on logical tasks, mirroring well-documented phenomena in human reasoning. Using controlled syllogistic reasoning experiments, our findings reveal that LLMs conflate logical validity with real-world plausibility. Through representational analysis, we demonstrate how validity and plausibility become entangled in the model's internal representations and explore interpretability techniques as tools for debiasing models to reason more formally. 2. Teaching systematic generalization through meta-learning. We investigated whether meta-learning could teach small language models to systematically apply logical rules. Inspired by systematic generalization in human cognition, we show that meta-learning enables models to apply inference rules from syllogistic logic to entirely novel premise structures, achieving both compositional generalization (handling shorter inference chains) and recursive generalization (handling longer chains). Together, these studies demonstrate how insights from human cognition can help us better understand and design models that are more systematic reasoners.</em>
        </p>
      </div>

      <div class="speaker">
        <strong>Manuel Vargas Guzmán</strong>
        (<span class="muted">University of Warsaw</span>)
        <p class="muted" style="margin-top:6px; text-align: justify;">            
          <em>TBA</em>
        </p>
      </div>            
    </section>

    <!-- Venue 
    <section id="venue">
      <h2>Venue</h2>
      <p class="muted">Venue: <strong><a href="https://palacstaszica.pan.pl/en/home/" target="_blank" rel="noopener">Staszic Palace</a> — Warsaw</strong><br>
      Date: <strong>January 8, 2026</strong></p>
      <a href="https://www.google.pl/maps/place/Pa%C5%82ac+Staszica/@52.2381921,21.0169431,18z/data=!4m14!1m7!3m6!1s0x471ecc5f9fdb37cf:0x3ea64800103394e6!2sPa%C5%82ac+Staszica!8m2!3d52.2379633!4d21.0181518!16s%2Fm%2F0273p13!3m5!1s0x471ecc5f9fdb37cf:0x3ea64800103394e6!8m2!3d52.2379633!4d21.0181518!16s%2Fm%2F0273p13?entry=ttu&g_ep=EgoyMDI1MTAyMi4wIKXMDSoASAFQAw%3D%3D" 
       target="_blank" 
       style="color:var(--accent); text-decoration:none; font-weight:500;">
       How to reach the venue →
      </a>
    </section> -->

    <!-- Venue -->
    <section id="venue">
      <h2>Venue</h2>

      <p class="muted" style="text-align: justify;">
        The workshop will be held at the 
        <a href="https://ifispan.pl/en/" target="_blank" rel="noopener" style="color:var(--accent); text-decoration:none;">
          Institute of Philosophy and Sociology, Polish Academy of Sciences</a>, located in the 
        <a href="https://palacstaszica.pan.pl/en/home/" target="_blank" rel="noopener" style="color:var(--accent); text-decoration:none;">
          Staszic Palace</a>, a historic building in the heart of Warsaw:
        <br><br>
        ul. Nowy Świat 72<br>
        00-330 Warszawa<br>
        Poland
      </p>

      <p class="muted" style="text-align: justify;">
        <strong>How to reach the venue: 
          <a href="https://www.google.pl/maps/place/Instytut+Filozofii+i+Socjologii+PAN/@52.2377194,21.017891,17z/data=!3m1!4b1!4m6!3m5!1s0x471ecc5f9fdb37cf:0x91efae954b147ac0!8m2!3d52.2377194!4d21.017891!16s%2Fg%2F121f4bmp?entry=ttu&g_ep=EgoyMDI1MTAyMi4wIKXMDSoASAFQAw%3D%3D" 
             target="_blank" rel="noopener" style="color:var(--accent); text-decoration:none;">
            Google Maps
          </a>
        </strong>
      </p>

      <p class="muted" style="text-align: justify;">
        The venue is conveniently located near the University of Warsaw, with bus stops (Uniwersytet) and the M2 subway station (Nowy Świat-Uniwersytet) in close proximity. Tickets can be purchased from ticket machines (3.40 PLN for 20 minutes or 4.40 PLN for 70 minutes). The entrance to the Staszic Palace, home of the Institute, is easily identifiable by the 
        <a href="https://pl.wikipedia.org/wiki/Pa%C5%82ac_Staszica#/media/File:Nikolaus_Copernicus_Monument_Warsaw.jpg" target="_blank" rel="noopener" style="color:var(--accent); text-decoration:none;">
          Nicolaus Copernicus Monument
        </a>.
      </p>

      <p class="muted" style="text-align: justify;">
        The workshop sessions will take place on the third floor, in Room 268. 
        <details style="margin-top:6px;">
          <summary style="cursor:pointer; color:var(--accent);">Show Room Map</summary>
          <a href="images/268_lowres.png" target="_blank" rel="noopener" title="Click to open in a new tab">
            <img src="images/268_lowres.png" alt="Room 268 map" style="margin-top:6px; width:100%; max-width:600px; display:block;">
          </a>
        </details>
      </p>
    </section>

    <!-- Contact -->
    <section id="contact">
      <h2>Contact</h2>
      <p class="muted">
        For questions about the workshop, please contact us at:<br>
        <a href="mailto:compositionalityworkshop@gmail.com">compositionalityworkshop@gmail.com</a>
      </p>
    </section>

    <!-- Footer Section -->
    <footer>
      <div class="logo-container">
        <a href="https://www.uw.edu.pl/" target="_blank" rel="noopener">
          <img src="images/uw_logo.png" alt="University of Warsaw Logo">
        </a>
        <a href="https://www.unitn.it/" target="_blank" rel="noopener">
          <img src="images/ut_logo.jpg" alt="University of Trento Logo">
        </a>
        <a href="https://ifispan.pl/en/" target="_blank" rel="noopener">
          <img src="images/ifispan_logo.png" alt="IFIS PAN Logo" style="height:100px; width:auto;">
        </a>
      </div>
      <p>&copy; 2025 Compositionality &amp; Reasoning Workshop — University of Warsaw.</p>
    </footer>
  </div>
</body>
</html>
